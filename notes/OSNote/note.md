# 内存管理
## 前言  

早期直接使用物理地址访问内存进行编程，会面临以下几个重大问题:
- 动态分配和回收内存(程序运行时地址写死，既不利于分配也不利于回收)
- 内外部碎片问题
- 进程隔离和安全问题

为一个进程提供一对简单的基址/界限寄存器，实现虚拟地址到物理地址的简单映射，这样做有两个好处：  
- 进程的物理地址受到了基址寄存器的控制，不再写死;
- 界限寄存器提供了地址越界判断，保证了隔离和安全；

在这一层简单映射下，进程物理地址可通过基址寄存器重定位且受界限寄存器保护，然而还有以下显著问题:
- 堆区和栈区存在大块未使用的内存预留区域，产生内部碎片利用不充分
- 没有进程换入换出机制

## 分段
基于以上问题引入分段机制——将每个进程占用的虚拟空间划分为代码段/堆/栈几个逻辑分段，段寄存器内保存着每  
个逻辑分段提供一对逻辑基址/界限寄存器/反向位/保护标志位。尽管不存在内部碎片了，但还是有外部碎片。  
进程的物理地址可以通过显式规定段号来确定是哪个段，  段号 | 段内偏移
注意栈区的地址是反向增长，计算栈物理地址时注意取反
  
C语言的free(ptr)调用无需显式地指定释放内存块区域大小，是因为在malloc时候，实际分配的内存块前保存了  
一个header的内存块元数据,free只需在ptr地址前寻找到元数据就能获得释放的内存块大小，这个元数据不但保  
存着分配块内存的信息，还保存着空闲块内存的信息
堆内存的分配和回收都对应着空闲列表的分割和合并操作  
为空闲列表的分配空闲列表，底层是通过系统调用mmap()实现

# 分页
## 分页机制
只要分配内存大小不一，分段机制只能通过算法减少物理内存排布不紧凑的情况，但无法消除，引入更大的内存分配  
单元——内存分页机制。虚拟地址空间和物理地址空间的最小内存单元不再是字节而是页。对应的，以前的地址变成了
页号。虚拟地址也划分为页号和页内偏移，物理地址 = 页表映射\[页号\] + 页内偏移  
页表——记录着<虚拟页号, PTE>映射信息,保存在物理地址空间，页表寄存器保存着页表起始位置的物理地址。

PTE记录者页表项元信息，例如保护位/存在位/脏位/物理地址页号，决定着该页的读写执行模式以及当前页状态

## 分页管理技术-快速地址转换TLB
然而页表在被映射为物理地址的过程中有多次访存操作（先从内存查页表项，再查物理页号），因此空间和效率上都存在问题
为解决页表映射过程中的访存操作带来的效率问题，计算机的MMU硬件增加了一层缓存Cache(TLB)，每次访存  
前都会先查找访问TLB，同页元素的TLB命中。不同页元素会导致TLB不命中
TLB不命中后可以采取硬件处理，也可以引发中断让操作系统程序员处理  
TLB在进程切换时的策略问题：TLB项新增地址空间标识符ASID(类似于PID标识)  
TLB表项替换更新策略:LRC和随机采样<br><br>

页表本身保存着大量信息占据着大量内存空间，必须设法降低页表的内存占用开销。考虑采用以下思路：
## 段页结合
每个逻辑段，段基寄存器中保存着页表的物理地址，界限寄存器
## 多级页表
直接用页表存储<页号，PTE>映射信息会有如下问题:
- 大量无效页表项会被分配物理内存
- 内存的新增和回收限制较大


多级页表的概念与图形学的八叉树、BST的二叉存储理念非常类似，都是通过分级分而治之达到存储结构和查找效率的优化  
页表比喻为一本没有目录的书，一级页表就是这本书的目录，类比于为页表再创建一级页表映射  
虚拟页号再一次被拆分为:VPN = 目录索引 | 页表索引  
对页表这本书内的许多无效页(留白页)，后续不再为其分配物理空间  
![页表与多级页表](./页表与多级页表.png)
设定多级目录好处是更高的有效页表利用率，对应的代价就是TLB未命中时的多级查找
## 交换空间
随着多道程序的增多需要越来越多的页表，有限的物理内存空间已不足以满足这种需求了，为了获取比物理  
内存更大的寻址空间，计算机在硬盘上开辟了一部分专门的交换空间，用于暂时腾出内存中部分进程的页表。  
**访问不在物理内存上的页，称之为缺页和页错误。**  
操作系统后台会有页守护进程，当物理内存可用空间到达警戒线时自动进行换页操作
1. 页置换策略——最少最近使用LRU  
LRU策略在许多场景下例如纯随机作业，遵循局部性原理的作业，以及2-8特性的作业有较低的缺页率。  
然而它的本质决定了在顺序循环执行的作业中会一直发生缺页.  
完美的LRU机制实现代价太大，但有个近似的LRU机制——通过为页新增一个使用位，每次被调入物理内存  
时会使使用位置1，置零则由操作系统决定。CLOCK算法会遍历那些置零的页将他们换出并指针向下一页
由于一些页虽被置换然而并未被写入，置换掉这些未被改写的页代价很小(因为未被改动所以不需写入磁盘)，  
因此页新增一个脏位，内容要是被写入改动过则将脏位置1.
## 真实的虚拟地址空间——VAX/VMS虚拟内存系统
每个进程拥有32位地址空间且512字节的页(很小的分页，减少页表内存开销是首要问题)，每个地址空间  
分为了用户空间和系统空间，操作系统内核代码将被全部进程共享  
考虑到对空指针的支持，每个页号为0的PTE都标记为不可访问  
在VMS系统中，操作系统是通过切换P0/P1寄存器来达到换页而不是基址/界限寄存器换页  
VMS及许多现代操作系统都会引入惰性机制，例如写时复制等技术，来减小操作系统分配内存和配置页表时的开销

# 并发
每个线程有其独立的PC和栈区，但它们都共享同一进程地址空间，多线程难免会访问进程中同一代码段或数据段，  
另外又由于CPU的定时中断调度到其他线程，多个线程执行同一段代码引发的竞争情况，这种变量和代码区称为  
**临界区**，针对这一问题，POSIX标准使用互斥锁和信号量机制来避免这一竞争现象  
## 锁的实现
```C
pthread_mutex_t lock;
pthread_mutex_lock(&lock);
x = x + 1; // or whatever your critical section is
pthread_mutex_unlock(&lock)
```
进入临界区前检查是否有其他线程持有锁，若无锁则上锁并执行临界区代码，若持有锁，尝试获取该锁的线  
程将不会从该调用返回  
早期实现锁的机制(即lock和unlock调用的实现)如下:  
- CPU暂时关闭中断，让CPU执行完加锁临界区。但这样带来的后果和缺点是显而易见的;线程长期持有锁的饿死现象，不支持多CPU
- 设置自旋锁，锁被占用时将反复自旋检查，缺点是也有饿死现象，单CPU上浪费CPU周期，但自旋锁在多核CPU表现较好
- 当进程陷入自旋时，通过原语yield()主动让出CPU  

虽然主动让出能解决浪费CPU周期和饿死现象，然而多线程竞争同一锁时，线程上下文切换的代价较大且仍然存在
使用队列，用休眠态代替自旋态  
高效的锁机制需要硬件提供更强大的指令(例如x86的xchg),还需要操作系统的支持(如yield,park,unpark原语)  
多线程的并发调度上不仅仅是支持寄存器变量，而且还需支持常见的数据结构的并发操作，甚至还需要支持在多核CPU上的调度

## 条件变量
条件变量是用来实现线程的等待和阻塞逻辑，它和互斥锁一起使用，避免了线程在面临临界区资源冲突时，线程始终占用着CPU资源自旋。  
条件变量的引入会让自身进入阻塞态并释放互斥锁。
条件变量的典型使用场景包含：
- 生产者消费者问题
- 抽烟者问题
- 哲学家进餐问题
 
## 信号量机制(semaphore)  
信号量是更一般化的协调多线程合理有序使用临界区的机制，它记录着同一时间允许访问临界区资源的线程数  
信号量的lock和unlock操作称之wait和signal调用(也称之为P和V操作),线程在进入临界区前执行P，退出临界区后执行V  
- 整型信号量  
```C
int S = 1;
wait(int S)               
{                       
    while(S <= 0)			
    S = S-1              
}
signal(int S)
{
    S = S+1
}
```
由于整型信号量在资源数不足时执行的是while循环等待，违背了让权等待原则，因此改进整型信号量为记录型信号量
- 记录型信号量
```C
typedef struct {
    int value
    sturct process *L
} semaphore
wait (semaphore S){
    S.value--
    if(S.value < 0){
        block(S.L)
    }
}
signal(semaphore S){
    S.value++
    if(S.value <= 0){
        wakeup(S.L)
    }
}
```
记录型信号量P操作在面临资源不足时执行的是将自身放入阻塞队列，V操作在资源可用时会唤醒阻塞队列中的线程

## 常见并发问题
1. 非死锁
- 违反原子性操作
- 违反线程间执行顺序
2. 死锁  
死锁产生的四个条件:  
   - 互斥
   - 持有并等待
   - 非抢占
   - 循环等待

## 基于事件并发
上文提到的都是基于线程的并发，既各个线程抢占CPU的使用权，抢占调度规则统一由操作系统管理，操作系统会通过各种锁、条件变量  
信号量机制来实现线程的上下文切换达到多线程并发。基于线程并发方式适用于阻塞式I/O密集型场景，缺点是线程同步和上下文切换带  
来的开销以及死锁问题。  
而基于事件的并发，则是将所有任务放到单线程中，通过事件轮询来实现多任务的并发和调度。

# 持久化
## IO设备
一个标准IO设备应该向外提供:
- 状态、命令、数据  

采用CPU轮询模式的标准IO设备的协议包含四步骤:
1. 状态查询(是否可用，是否就绪)
2. 写入数据
3. 写入命令
4. 检查命令是否完成

对于低速IO，操作系统轮询的方式效率比较低下，因此中断是更合适的选择，然而高速IO情况恰好相反，中断的开销更高  
许多IO任务中都是CPU将内存数据与IO进行交换，通过DMA可以使得内存与IO直接进行交互，内存与IO数据传输不再需要CPU  
介入，提高了CPU的利用效率。

## 磁盘驱动器
磁盘驱动器不单单是永久存储信息的磁性介质，它还包含磁盘缓存Cache,磁盘调度程序  
为了实现磁盘系统的更大、更快和更可靠的设计目标，有一种将多个廉价较小磁盘构建在一起的技术——廉价冗余磁盘阵列RAID,  
RAID是一个非常专业的计算机系统(包含CPU内存和磁盘),它不运行应用程序，而是运行专门操作RAID的软件，RAID后面的  
编号并不是代数，而是不同RAID技术的代号